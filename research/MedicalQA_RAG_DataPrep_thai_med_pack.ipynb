{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38abdb5b",
   "metadata": {},
   "source": [
    "# Thai Medical QA / RAG — Dataset + Data Engineering Starter (Notebook)\n",
    "\n",
    "This notebook uses **Thaweewat/thai-med-pack** from Hugging Face and helps you:\n",
    "\n",
    "- Load + inspect the dataset (Thai medical Q&A style)\n",
    "- Parse instruction-style text into structured fields: `question`, `answer`\n",
    "- Do basic data engineering (cleaning, dedupe, privacy/PII-risk scan, safety filtering, split)\n",
    "- Build a retrieval corpus by chunking answers/contexts\n",
    "- Export `jsonl` files for model training / RAG indexing\n",
    "\n",
    "> ⚠️ Note: Some entries may include **sensitive topics** (e.g., sexual health, minors, mental health crises).  \n",
    "> For an academic MVP, you should **filter** sensitive content and keep the system as **decision-support only**.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b5ab4652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T03:20:25.820648443Z",
     "start_time": "2026-02-17T03:20:25.815705618Z"
    }
   },
   "source": [
    "# If needed, install deps (uncomment)\n",
    "# !pip install -U datasets pandas\n",
    "\n",
    "import re, json, os, random, hashlib\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "0ad545f2",
   "metadata": {},
   "source": [
    "## 1) Load dataset: Thaweewat/thai-med-pack\n",
    "\n",
    "This dataset is provided as an instruction-style text field (typically one column: `text`).\n",
    "We'll load the `train` split and parse the `[INST] ... [/INST]` part into question & answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e2e44eff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T03:20:43.236390300Z",
     "start_time": "2026-02-17T03:20:27.852325559Z"
    }
   },
   "source": [
    "ds = load_dataset(\"Thaweewat/thai-med-pack\")\n",
    "# Typically only 'train' split is provided\n",
    "df_raw = ds[list(ds.keys())[0]].to_pandas()\n",
    "df_raw.head()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Generating train split: 100%|██████████| 189190/189190 [00:00<00:00, 215524.59 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                text\n",
       "0  <s>[INST] สวัสดีค่ะ อยากรู้ว่าต้องทำยังไงคะมีอ...\n",
       "1  <s>[INST] อยากทราบว่ากินยาคลุมฉุกเฉินชนิด 1 เม...\n",
       "2  <s>[INST] ไม่รู้ว่าใช่ประจำเดือนหรือป่าว แต่เล...\n",
       "3  <s>[INST] ตอนนี้หนูอายุ13ปีและหนูเป็นนางรำของร...\n",
       "4  <s>[INST] ตามต้นหัวข้อเลยค่ะ เราเป็นคนที่คิดมา..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;[INST] สวัสดีค่ะ อยากรู้ว่าต้องทำยังไงคะมีอ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;[INST] อยากทราบว่ากินยาคลุมฉุกเฉินชนิด 1 เม...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;s&gt;[INST] ไม่รู้ว่าใช่ประจำเดือนหรือป่าว แต่เล...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt;[INST] ตอนนี้หนูอายุ13ปีและหนูเป็นนางรำของร...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt;[INST] ตามต้นหัวข้อเลยค่ะ เราเป็นคนที่คิดมา...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "ae521ace",
   "metadata": {},
   "source": [
    "## 2) Parse instruction format into structured QA\n",
    "\n",
    "Expected pattern in `text` (example):\n",
    "- `<s>[INST] ...question... [/INST] ...answer... </s>`\n",
    "\n",
    "We will extract:\n",
    "- `question`\n",
    "- `answer`\n",
    "\n",
    "If an entry does not match the pattern, it will be dropped (or kept in `unparsed` for audit).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c14cc422",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T03:20:57.664877269Z",
     "start_time": "2026-02-17T03:20:49.788248389Z"
    }
   },
   "source": [
    "WS_RE = re.compile(r\"\\s+\")\n",
    "INST_RE = re.compile(r\"\\[INST\\](.*?)\\[/INST\\](.*)\", re.DOTALL)\n",
    "\n",
    "def sha1(text: str) -> str:\n",
    "    return hashlib.sha1(text.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
    "\n",
    "def clean_text(s) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"\\u00a0\", \" \")\n",
    "    s = WS_RE.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def parse_inst(sample: str):\n",
    "    if not sample:\n",
    "        return None, None\n",
    "    m = INST_RE.search(sample)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    q = clean_text(m.group(1))\n",
    "    a = clean_text(m.group(2))\n",
    "    # strip common special tokens\n",
    "    q = q.replace(\"<s>\", \"\").replace(\"</s>\", \"\").strip()\n",
    "    a = a.replace(\"<s>\", \"\").replace(\"</s>\", \"\").strip()\n",
    "    return q, a\n",
    "\n",
    "# Parse\n",
    "text_col = \"text\"\n",
    "if text_col not in df_raw.columns:\n",
    "    # Sometimes datasets use 'prompt' or similar; fallback: first column\n",
    "    text_col = df_raw.columns[0]\n",
    "\n",
    "parsed = df_raw[text_col].map(parse_inst)\n",
    "df = pd.DataFrame(parsed.tolist(), columns=[\"question\", \"answer\"])\n",
    "\n",
    "# Keep raw for auditing if needed\n",
    "df[\"raw_text\"] = df_raw[text_col].astype(str).map(lambda x: x[:5000])  # cap length\n",
    "\n",
    "# Drop unparsed\n",
    "unparsed = df[df[\"question\"].isna() | df[\"answer\"].isna()].copy()\n",
    "df = df.dropna(subset=[\"question\", \"answer\"]).reset_index(drop=True)\n",
    "\n",
    "# Make stable id\n",
    "df[\"id\"] = [sha1(f\"{q}||{a}||{i}\") for i, (q, a) in enumerate(zip(df[\"question\"], df[\"answer\"]))]\n",
    "\n",
    "df = df[[\"id\", \"question\", \"answer\", \"raw_text\"]]\n",
    "df.head(), len(df), len(unparsed)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                         id  \\\n",
       " 0  cc79cd4e61194d7f30c078bd9f54aa0c94c43f64   \n",
       " 1  f21051455d5c19c9b7b52096b4fafc3abc7bc88c   \n",
       " 2  ca64cdd9d62e666f9c72debdbc24945302529c5a   \n",
       " 3  1e348c10ee823d318858e51c7fddea63a0344ac2   \n",
       " 4  bd311f898481fe58d118026962b1be27795adbc3   \n",
       " \n",
       "                                             question  \\\n",
       " 0  สวัสดีค่ะ อยากรู้ว่าต้องทำยังไงคะมีอาการคันอวั...   \n",
       " 1  อยากทราบว่ากินยาคลุมฉุกเฉินชนิด 1 เม็ด แล้วประ...   \n",
       " 2  ไม่รู้ว่าใช่ประจำเดือนหรือป่าว แต่เลือกมันเป็น...   \n",
       " 3  ตอนนี้หนูอายุ13ปีและหนูเป็นนางรำของร.ร.แต่หนูร...   \n",
       " 4  ตามต้นหัวข้อเลยค่ะ เราเป็นคนที่คิดมากอยู่แล้ว ...   \n",
       " \n",
       "                                               answer  \\\n",
       " 0  สวัสดีค่ะ อาการคันอวัยวะเพศหญิง อาจเกิดจาก-รูข...   \n",
       " 1  สวัสดีค่ะ หลังใข้ยาคุมฉุกเฉินอาจทำให้มีเลือดออ...   \n",
       " 2  สวัสดีค่ะ หากเลือดที่ออก อยู่ในช่วงวันที่ประจำ...   \n",
       " 3  สวัสดีค่ะ ฟังจากเหตุการณ์และความคิดของ น่าจะมี...   \n",
       " 4  สวัสดีค่ะ อาการร้องไห้ง่ายขึ้น มีพฤติกรรมทำร้า...   \n",
       " \n",
       "                                             raw_text  \n",
       " 0  <s>[INST] สวัสดีค่ะ อยากรู้ว่าต้องทำยังไงคะมีอ...  \n",
       " 1  <s>[INST] อยากทราบว่ากินยาคลุมฉุกเฉินชนิด 1 เม...  \n",
       " 2  <s>[INST] ไม่รู้ว่าใช่ประจำเดือนหรือป่าว แต่เล...  \n",
       " 3  <s>[INST] ตอนนี้หนูอายุ13ปีและหนูเป็นนางรำของร...  \n",
       " 4  <s>[INST] ตามต้นหัวข้อเลยค่ะ เราเป็นคนที่คิดมา...  ,\n",
       " 189190,\n",
       " 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "0d85f406",
   "metadata": {},
   "source": [
    "## 3) Privacy / PDPA + Safety filtering (recommended)\n",
    "\n",
    "Even if this is a public dataset, the content may include:\n",
    "- **minors** (age stated)\n",
    "- sensitive sexual health topics\n",
    "- mental health crises / self-harm mentions\n",
    "\n",
    "We will:\n",
    "1) Do a **conservative PII-risk scan** (email/phone/Thai ID format)  \n",
    "2) Optionally filter **high-risk sensitive content** using keyword heuristics (editable list)\n",
    "\n",
    "> This is NOT perfect. Treat it as an engineering safeguard + audit trail.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "80dd3f82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T03:21:40.331874562Z",
     "start_time": "2026-02-17T03:20:57.665820941Z"
    }
   },
   "source": [
    "EMAIL_RE = re.compile(r\"\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\\b\", re.I)\n",
    "PHONE_RE = re.compile(r\"\\b(?:\\+?\\d{1,3}[- ]?)?(?:\\(?\\d{2,3}\\)?[- ]?)?\\d{3}[- ]?\\d{4}\\b\")\n",
    "THAI_ID_RE = re.compile(r\"\\b\\d{1}-\\d{4}-\\d{5}-\\d{2}-\\d\\b\")\n",
    "\n",
    "# Sensitive-topic heuristics (tune for your project)\n",
    "SENSITIVE_PATTERNS = [\n",
    "    r\"ฆ่าตัวตาย\", r\"ทำร้ายตัวเอง\", r\"กรีด\", r\"ผูกคอ\", r\"อยากตาย\",\n",
    "    r\"ข่มขืน\", r\"ล่วงละเมิด\",\n",
    "]\n",
    "SENSITIVE_RE = re.compile(\"|\".join(SENSITIVE_PATTERNS))\n",
    "\n",
    "def pii_risk_flag(text: str) -> bool:\n",
    "    if not text:\n",
    "        return False\n",
    "    if EMAIL_RE.search(text): return True\n",
    "    if THAI_ID_RE.search(text): return True\n",
    "    if PHONE_RE.search(text): return True\n",
    "    return False\n",
    "\n",
    "def sensitive_flag(text: str) -> bool:\n",
    "    if not text:\n",
    "        return False\n",
    "    return bool(SENSITIVE_RE.search(text))\n",
    "\n",
    "flags_pii = df.apply(lambda r: pii_risk_flag(r[\"question\"]) or pii_risk_flag(r[\"answer\"]), axis=1)\n",
    "flags_sensitive = df.apply(lambda r: sensitive_flag(r[\"question\"]) or sensitive_flag(r[\"answer\"]), axis=1)\n",
    "\n",
    "df_pii_flagged = df[flags_pii].copy()\n",
    "df_sensitive_flagged = df[flags_sensitive].copy()\n",
    "\n",
    "df_kept = df[~(flags_pii | flags_sensitive)].copy().reset_index(drop=True)\n",
    "\n",
    "len(df), len(df_kept), len(df_pii_flagged), len(df_sensitive_flagged)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189190, 186172, 358, 2667)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "2489e94c",
   "metadata": {},
   "source": [
    "## 4) Dedupe + clean\n",
    "\n",
    "- Dedupe by `(question, answer)`\n",
    "- Drop empty rows\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "39b5c621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T03:21:43.372742527Z",
     "start_time": "2026-02-17T03:21:40.344293620Z"
    }
   },
   "source": [
    "def dedupe(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    tmp = df_in.copy()\n",
    "    tmp[\"_key\"] = (tmp[\"question\"].fillna(\"\") + \"||\" + tmp[\"answer\"].fillna(\"\")).map(sha1)\n",
    "    tmp = tmp.drop_duplicates(subset=[\"_key\"]).drop(columns=[\"_key\"]).reset_index(drop=True)\n",
    "    return tmp\n",
    "\n",
    "df_clean = dedupe(df_kept)\n",
    "df_clean = df_clean[(df_clean[\"question\"].str.len() > 0) & (df_clean[\"answer\"].str.len() > 0)].reset_index(drop=True)\n",
    "\n",
    "df_clean.shape\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186059, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "71edffd5",
   "metadata": {},
   "source": [
    "## 5) Split Train/Val/Test\n",
    "\n",
    "This dataset may not have labels, so we do a random split by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2c938a98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T03:21:44.358534254Z",
     "start_time": "2026-02-17T03:21:43.385194579Z"
    }
   },
   "source": [
    "def random_split(df_in: pd.DataFrame, train=0.8, val=0.1, test=0.1, seed=RANDOM_SEED):\n",
    "    assert abs(train + val + test - 1.0) < 1e-9\n",
    "    idx = list(df_in.index)\n",
    "    rng = random.Random(seed)\n",
    "    rng.shuffle(idx)\n",
    "    n = len(idx)\n",
    "    n_train = int(n * train)\n",
    "    n_val = int(n * val)\n",
    "    train_df = df_in.loc[idx[:n_train]].reset_index(drop=True)\n",
    "    val_df = df_in.loc[idx[n_train:n_train+n_val]].reset_index(drop=True)\n",
    "    test_df = df_in.loc[idx[n_train+n_val:]].reset_index(drop=True)\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = random_split(df_clean, 0.8, 0.1, 0.1)\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148847, 18605, 18607)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "6018f07e",
   "metadata": {},
   "source": [
    "## 6) Build retrieval corpus (chunk answers)\n",
    "\n",
    "For a simple RAG baseline, we can index the **answers** (or combine question+answer).\n",
    "If you later add external guideline PDFs, replace this with guideline chunking.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4897d682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T03:22:02.372919086Z",
     "start_time": "2026-02-17T03:21:44.374270953Z"
    }
   },
   "source": [
    "def chunk_text(text: str, max_chars: int = 900, overlap: int = 120):\n",
    "    text = clean_text(text)\n",
    "    if not text:\n",
    "        return []\n",
    "    # sentence-ish split (Thai doesn't use periods consistently; still helps a bit)\n",
    "    sents = re.split(r\"(?<=[.!?。！？])\\s+\", text)\n",
    "    chunks, cur = [], \"\"\n",
    "    for s in sents:\n",
    "        if not s:\n",
    "            continue\n",
    "        if len(cur) + 1 + len(s) <= max_chars:\n",
    "            cur = (cur + \" \" + s).strip()\n",
    "        else:\n",
    "            if cur:\n",
    "                chunks.append(cur)\n",
    "            cur = s\n",
    "    if cur:\n",
    "        chunks.append(cur)\n",
    "\n",
    "    final = []\n",
    "    for ch in chunks:\n",
    "        if len(ch) <= max_chars:\n",
    "            final.append(ch)\n",
    "        else:\n",
    "            start = 0\n",
    "            while start < len(ch):\n",
    "                final.append(ch[start:start + max_chars])\n",
    "                start += max(1, max_chars - overlap)\n",
    "    return final\n",
    "\n",
    "def build_corpus(df_in: pd.DataFrame, max_chars=900):\n",
    "    rows = []\n",
    "    for _, r in df_in.iterrows():\n",
    "        doc_id = r[\"id\"]\n",
    "        # Index answer alone, or (Q+A) if you prefer:\n",
    "        base = f\"Q: {r['question']}\\nA: {r['answer']}\"\n",
    "        for j, ch in enumerate(chunk_text(base, max_chars=max_chars, overlap=max(20, int(max_chars*0.15)))):\n",
    "            rows.append({\"doc_id\": doc_id, \"chunk_id\": f\"{doc_id}-{j:03d}\", \"text\": ch})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "corpus_df = build_corpus(train_df, max_chars=900)\n",
    "corpus_df.head(), len(corpus_df)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                     doc_id  \\\n",
       " 0  cf4f80246e8f4aa4527acde329e708728ef2fb85   \n",
       " 1  8a119092792fd342caa44cd757208b9b60b0cef2   \n",
       " 2  8a119092792fd342caa44cd757208b9b60b0cef2   \n",
       " 3  bf96be8699b1126bff81647bbe4bc236ae49e269   \n",
       " 4  bf96be8699b1126bff81647bbe4bc236ae49e269   \n",
       " \n",
       "                                        chunk_id  \\\n",
       " 0  cf4f80246e8f4aa4527acde329e708728ef2fb85-000   \n",
       " 1  8a119092792fd342caa44cd757208b9b60b0cef2-000   \n",
       " 2  8a119092792fd342caa44cd757208b9b60b0cef2-001   \n",
       " 3  bf96be8699b1126bff81647bbe4bc236ae49e269-000   \n",
       " 4  bf96be8699b1126bff81647bbe4bc236ae49e269-001   \n",
       " \n",
       "                                                 text  \n",
       " 0  Q: ผมโดนเเมวข่วนแมวยังไม่ฉีดยาพึ่งอายุ2เดือนกว...  \n",
       " 1  Q: เป็นเวลาหนึ่งสัปดาห์แล้วที่ฉันรู้สึกแสบท้อง...  \n",
       " 2  ราโซล 20 มก., แพนโทพราโซล 40 มก., โอเมพราโซล 2...  \n",
       " 3  Q: คืิผมอานุแค่14ครับมีตุ่ทที่โคนลิ้นเจ็บไม่เจ...  \n",
       " 4  เป็นอาการแสดงของโรคติดเชื้อต่างๆ เช่น โรคมือเท...  ,\n",
       " 225332)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "b9b5a470",
   "metadata": {},
   "source": [
    "## 7) Export JSONL (+ audit files)\n",
    "\n",
    "Outputs:\n",
    "- `qa_train.jsonl`, `qa_val.jsonl`, `qa_test.jsonl`\n",
    "- `corpus.jsonl`\n",
    "- `pii_flagged.jsonl` (audit)\n",
    "- `sensitive_flagged.jsonl` (audit)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ad6551d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T03:22:07.332487254Z",
     "start_time": "2026-02-17T03:22:02.390511718Z"
    }
   },
   "source": [
    "def to_jsonl(df_in: pd.DataFrame, path: str):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for row in df_in.to_dict(orient=\"records\"):\n",
    "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "outdir = \"out_thai_med_pack\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "to_jsonl(train_df.drop(columns=[\"raw_text\"]), os.path.join(outdir, \"qa_train.jsonl\"))\n",
    "to_jsonl(val_df.drop(columns=[\"raw_text\"]),   os.path.join(outdir, \"qa_val.jsonl\"))\n",
    "to_jsonl(test_df.drop(columns=[\"raw_text\"]),  os.path.join(outdir, \"qa_test.jsonl\"))\n",
    "to_jsonl(corpus_df, os.path.join(outdir, \"corpus.jsonl\"))\n",
    "\n",
    "if len(df_pii_flagged) > 0:\n",
    "    to_jsonl(df_pii_flagged, os.path.join(outdir, \"pii_flagged.jsonl\"))\n",
    "if len(df_sensitive_flagged) > 0:\n",
    "    to_jsonl(df_sensitive_flagged, os.path.join(outdir, \"sensitive_flagged.jsonl\"))\n",
    "\n",
    "stats = {\n",
    "    \"rows_total_parsed\": int(len(df)),\n",
    "    \"rows_unparsed\": int(len(unparsed)),\n",
    "    \"rows_after_filters\": int(len(df_clean)),\n",
    "    \"train\": int(len(train_df)),\n",
    "    \"val\": int(len(val_df)),\n",
    "    \"test\": int(len(test_df)),\n",
    "    \"corpus_chunks_train\": int(len(corpus_df)),\n",
    "    \"pii_flagged\": int(len(df_pii_flagged)),\n",
    "    \"sensitive_flagged\": int(len(df_sensitive_flagged)),\n",
    "}\n",
    "with open(os.path.join(outdir, \"stats.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(stats, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "stats\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rows_total_parsed': 189190,\n",
       " 'rows_unparsed': 0,\n",
       " 'rows_after_filters': 186059,\n",
       " 'train': 148847,\n",
       " 'val': 18605,\n",
       " 'test': 18607,\n",
       " 'corpus_chunks_train': 225332,\n",
       " 'pii_flagged': 358,\n",
       " 'sensitive_flagged': 2667}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "2de21585",
   "metadata": {},
   "source": [
    "## 8) What to write in your proposal/report (copy-paste starter)\n",
    "\n",
    "**Dataset & Data Description**\n",
    "- Source: Hugging Face dataset `Thaweewat/thai-med-pack`\n",
    "- Modality: Thai medical Q&A instruction-style text\n",
    "- Size: ~189k rows (train split)\n",
    "- Split: Created locally (80/10/10)\n",
    "\n",
    "**Privacy / PDPA / Ethics**\n",
    "- Content may include sensitive health topics and minors; treat as potentially sensitive.\n",
    "- Mitigations: PII heuristic scan + sensitive-topic filter + audit outputs.\n",
    "- Risk if wrong: incorrect health guidance -> require disclaimers, escalation rules, and “decision-support only”.\n",
    "\n",
    "**Data Engineering**\n",
    "- Parse instruction format, dedupe, drop unparsed/empty.\n",
    "- Sampling: random split (no labels).\n",
    "- Assumptions: parsed Q/A reflect intended supervision signal; filtering reduces harmful/sensitive content exposure.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
