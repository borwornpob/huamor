{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "38abdb5b",
      "metadata": {
        "id": "38abdb5b"
      },
      "source": [
        "# Thai Medical QA / RAG — Dataset + Data Engineering Starter (Notebook)\n",
        "\n",
        "This notebook uses **Thaweewat/thai-med-pack** from Hugging Face and helps you:\n",
        "\n",
        "- Load + inspect the dataset (Thai medical Q&A style)\n",
        "- Parse instruction-style text into structured fields: `question`, `answer`\n",
        "- Do basic data engineering (cleaning, dedupe, privacy/PII-risk scan, safety filtering, split)\n",
        "- Build a retrieval corpus by chunking answers/contexts\n",
        "- Export `jsonl` files for model training / RAG indexing\n",
        "\n",
        "> ⚠️ Note: Some entries may include **sensitive topics** (e.g., sexual health, minors, mental health crises).  \n",
        "> For an academic MVP, you should **filter** sensitive content and keep the system as **decision-support only**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b5ab4652",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-17T03:20:25.820648443Z",
          "start_time": "2026-02-17T03:20:25.815705618Z"
        },
        "id": "b5ab4652"
      },
      "outputs": [],
      "source": [
        "# If needed, install deps (uncomment)\n",
        "# !pip install -U datasets pandas\n",
        "\n",
        "import re, json, os, random, hashlib\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import tqdm as notebook_tqdm\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad545f2",
      "metadata": {
        "id": "0ad545f2"
      },
      "source": [
        "## 1) Load dataset: Thaweewat/thai-med-pack\n",
        "\n",
        "This dataset is provided as an instruction-style text field (typically one column: `text`).\n",
        "We'll load the `train` split and parse the `[INST] ... [/INST]` part into question & answer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e2e44eff",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-17T03:20:43.236390300Z",
          "start_time": "2026-02-17T03:20:27.852325559Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "e2e44eff",
        "outputId": "75ac62f5-18e9-400a-d78b-19a91981badb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_raw"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-33b9db3f-c85b-4643-a8c2-4dd35b0352bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt;[INST] สวัสดีค่ะ อยากรู้ว่าต้องทำยังไงคะมีอ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt;[INST] อยากทราบว่ากินยาคลุมฉุกเฉินชนิด 1 เม...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt;[INST] ไม่รู้ว่าใช่ประจำเดือนหรือป่าว แต่เล...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt;[INST] ตอนนี้หนูอายุ13ปีและหนูเป็นนางรำของร...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt;[INST] ตามต้นหัวข้อเลยค่ะ เราเป็นคนที่คิดมา...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33b9db3f-c85b-4643-a8c2-4dd35b0352bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33b9db3f-c85b-4643-a8c2-4dd35b0352bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33b9db3f-c85b-4643-a8c2-4dd35b0352bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text\n",
              "0  <s>[INST] สวัสดีค่ะ อยากรู้ว่าต้องทำยังไงคะมีอ...\n",
              "1  <s>[INST] อยากทราบว่ากินยาคลุมฉุกเฉินชนิด 1 เม...\n",
              "2  <s>[INST] ไม่รู้ว่าใช่ประจำเดือนหรือป่าว แต่เล...\n",
              "3  <s>[INST] ตอนนี้หนูอายุ13ปีและหนูเป็นนางรำของร...\n",
              "4  <s>[INST] ตามต้นหัวข้อเลยค่ะ เราเป็นคนที่คิดมา..."
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds = load_dataset(\"Thaweewat/thai-med-pack\")\n",
        "# Typically only 'train' split is provided\n",
        "df_raw = ds[list(ds.keys())[0]].to_pandas()\n",
        "df_raw.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae521ace",
      "metadata": {
        "id": "ae521ace"
      },
      "source": [
        "## 2) Parse instruction format into structured QA\n",
        "\n",
        "Expected pattern in `text` (example):\n",
        "- `<s>[INST] ...question... [/INST] ...answer... </s>`\n",
        "\n",
        "We will extract:\n",
        "- `question`\n",
        "- `answer`\n",
        "\n",
        "If an entry does not match the pattern, it will be dropped (or kept in `unparsed` for audit).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c14cc422",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-17T03:20:57.664877269Z",
          "start_time": "2026-02-17T03:20:49.788248389Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c14cc422",
        "outputId": "52dc2309-bbf5-4246-f86a-9c6c65879c23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(                                         id  \\\n",
              " 0  cc79cd4e61194d7f30c078bd9f54aa0c94c43f64   \n",
              " 1  f21051455d5c19c9b7b52096b4fafc3abc7bc88c   \n",
              " 2  ca64cdd9d62e666f9c72debdbc24945302529c5a   \n",
              " 3  1e348c10ee823d318858e51c7fddea63a0344ac2   \n",
              " 4  bd311f898481fe58d118026962b1be27795adbc3   \n",
              " \n",
              "                                             question  \\\n",
              " 0  สวัสดีค่ะ อยากรู้ว่าต้องทำยังไงคะมีอาการคันอวั...   \n",
              " 1  อยากทราบว่ากินยาคลุมฉุกเฉินชนิด 1 เม็ด แล้วประ...   \n",
              " 2  ไม่รู้ว่าใช่ประจำเดือนหรือป่าว แต่เลือกมันเป็น...   \n",
              " 3  ตอนนี้หนูอายุ13ปีและหนูเป็นนางรำของร.ร.แต่หนูร...   \n",
              " 4  ตามต้นหัวข้อเลยค่ะ เราเป็นคนที่คิดมากอยู่แล้ว ...   \n",
              " \n",
              "                                               answer  \\\n",
              " 0  สวัสดีค่ะ อาการคันอวัยวะเพศหญิง อาจเกิดจาก-รูข...   \n",
              " 1  สวัสดีค่ะ หลังใข้ยาคุมฉุกเฉินอาจทำให้มีเลือดออ...   \n",
              " 2  สวัสดีค่ะ หากเลือดที่ออก อยู่ในช่วงวันที่ประจำ...   \n",
              " 3  สวัสดีค่ะ ฟังจากเหตุการณ์และความคิดของ น่าจะมี...   \n",
              " 4  สวัสดีค่ะ อาการร้องไห้ง่ายขึ้น มีพฤติกรรมทำร้า...   \n",
              " \n",
              "                                             raw_text  \n",
              " 0  <s>[INST] สวัสดีค่ะ อยากรู้ว่าต้องทำยังไงคะมีอ...  \n",
              " 1  <s>[INST] อยากทราบว่ากินยาคลุมฉุกเฉินชนิด 1 เม...  \n",
              " 2  <s>[INST] ไม่รู้ว่าใช่ประจำเดือนหรือป่าว แต่เล...  \n",
              " 3  <s>[INST] ตอนนี้หนูอายุ13ปีและหนูเป็นนางรำของร...  \n",
              " 4  <s>[INST] ตามต้นหัวข้อเลยค่ะ เราเป็นคนที่คิดมา...  ,\n",
              " 189190,\n",
              " 0)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "WS_RE = re.compile(r\"\\s+\")\n",
        "INST_RE = re.compile(r\"\\[INST\\](.*?)\\[/INST\\](.*)\", re.DOTALL)\n",
        "\n",
        "def sha1(text: str) -> str:\n",
        "    return hashlib.sha1(text.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
        "\n",
        "def clean_text(s) -> str:\n",
        "    if s is None:\n",
        "        return \"\"\n",
        "    s = str(s).replace(\"\\u00a0\", \" \")\n",
        "    s = WS_RE.sub(\" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def parse_inst(sample: str):\n",
        "    if not sample:\n",
        "        return None, None\n",
        "    m = INST_RE.search(sample)\n",
        "    if not m:\n",
        "        return None, None\n",
        "    q = clean_text(m.group(1))\n",
        "    a = clean_text(m.group(2))\n",
        "    # strip common special tokens\n",
        "    q = q.replace(\"<s>\", \"\").replace(\"</s>\", \"\").strip()\n",
        "    a = a.replace(\"<s>\", \"\").replace(\"</s>\", \"\").strip()\n",
        "    return q, a\n",
        "\n",
        "# Parse\n",
        "text_col = \"text\"\n",
        "if text_col not in df_raw.columns:\n",
        "    # Sometimes datasets use 'prompt' or similar; fallback: first column\n",
        "    text_col = df_raw.columns[0]\n",
        "\n",
        "parsed = df_raw[text_col].map(parse_inst)\n",
        "df = pd.DataFrame(parsed.tolist(), columns=[\"question\", \"answer\"])\n",
        "\n",
        "# Keep raw for auditing if needed\n",
        "df[\"raw_text\"] = df_raw[text_col].astype(str).map(lambda x: x[:5000])  # cap length\n",
        "\n",
        "# Drop unparsed\n",
        "unparsed = df[df[\"question\"].isna() | df[\"answer\"].isna()].copy()\n",
        "df = df.dropna(subset=[\"question\", \"answer\"]).reset_index(drop=True)\n",
        "\n",
        "# Make stable id\n",
        "df[\"id\"] = [sha1(f\"{q}||{a}||{i}\") for i, (q, a) in enumerate(zip(df[\"question\"], df[\"answer\"]))]\n",
        "\n",
        "df = df[[\"id\", \"question\", \"answer\", \"raw_text\"]]\n",
        "df.head(), len(df), len(unparsed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d85f406",
      "metadata": {
        "id": "0d85f406"
      },
      "source": [
        "## 3) Privacy / PDPA + Safety filtering (recommended)\n",
        "\n",
        "Even if this is a public dataset, the content may include:\n",
        "- **minors** (age stated)\n",
        "- sensitive sexual health topics\n",
        "- mental health crises / self-harm mentions\n",
        "\n",
        "We will:\n",
        "1) Do a **conservative PII-risk scan** (email/phone/Thai ID format)  \n",
        "2) Optionally filter **high-risk sensitive content** using keyword heuristics (editable list)\n",
        "\n",
        "> This is NOT perfect. Treat it as an engineering safeguard + audit trail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "80dd3f82",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-17T03:21:40.331874562Z",
          "start_time": "2026-02-17T03:20:57.665820941Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80dd3f82",
        "outputId": "8ac66099-6a38-457f-a024-00aed97a5398"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(189190, 186172, 358, 2667)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EMAIL_RE = re.compile(r\"\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\\b\", re.I)\n",
        "PHONE_RE = re.compile(r\"\\b(?:\\+?\\d{1,3}[- ]?)?(?:\\(?\\d{2,3}\\)?[- ]?)?\\d{3}[- ]?\\d{4}\\b\")\n",
        "THAI_ID_RE = re.compile(r\"\\b\\d{1}-\\d{4}-\\d{5}-\\d{2}-\\d\\b\")\n",
        "\n",
        "# Sensitive-topic heuristics (tune for your project)\n",
        "SENSITIVE_PATTERNS = [\n",
        "    r\"ฆ่าตัวตาย\", r\"ทำร้ายตัวเอง\", r\"กรีด\", r\"ผูกคอ\", r\"อยากตาย\",\n",
        "    r\"ข่มขืน\", r\"ล่วงละเมิด\",\n",
        "]\n",
        "SENSITIVE_RE = re.compile(\"|\".join(SENSITIVE_PATTERNS))\n",
        "\n",
        "def pii_risk_flag(text: str) -> bool:\n",
        "    if not text:\n",
        "        return False\n",
        "    if EMAIL_RE.search(text): return True\n",
        "    if THAI_ID_RE.search(text): return True\n",
        "    if PHONE_RE.search(text): return True\n",
        "    return False\n",
        "\n",
        "def sensitive_flag(text: str) -> bool:\n",
        "    if not text:\n",
        "        return False\n",
        "    return bool(SENSITIVE_RE.search(text))\n",
        "\n",
        "flags_pii = df.apply(lambda r: pii_risk_flag(r[\"question\"]) or pii_risk_flag(r[\"answer\"]), axis=1)\n",
        "flags_sensitive = df.apply(lambda r: sensitive_flag(r[\"question\"]) or sensitive_flag(r[\"answer\"]), axis=1)\n",
        "\n",
        "df_pii_flagged = df[flags_pii].copy()\n",
        "df_sensitive_flagged = df[flags_sensitive].copy()\n",
        "\n",
        "df_kept = df[~(flags_pii | flags_sensitive)].copy().reset_index(drop=True)\n",
        "\n",
        "len(df), len(df_kept), len(df_pii_flagged), len(df_sensitive_flagged)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2489e94c",
      "metadata": {
        "id": "2489e94c"
      },
      "source": [
        "## 4) Dedupe + clean\n",
        "\n",
        "- Dedupe by `(question, answer)`\n",
        "- Drop empty rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "39b5c621",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-17T03:21:43.372742527Z",
          "start_time": "2026-02-17T03:21:40.344293620Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39b5c621",
        "outputId": "94c47a34-8587-4e09-8636-09e814594c1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(186059, 4)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def dedupe(df_in: pd.DataFrame) -> pd.DataFrame:\n",
        "    tmp = df_in.copy()\n",
        "    tmp[\"_key\"] = (tmp[\"question\"].fillna(\"\") + \"||\" + tmp[\"answer\"].fillna(\"\")).map(sha1)\n",
        "    tmp = tmp.drop_duplicates(subset=[\"_key\"]).drop(columns=[\"_key\"]).reset_index(drop=True)\n",
        "    return tmp\n",
        "\n",
        "df_clean = dedupe(df_kept)\n",
        "df_clean = df_clean[(df_clean[\"question\"].str.len() > 0) & (df_clean[\"answer\"].str.len() > 0)].reset_index(drop=True)\n",
        "\n",
        "df_clean.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71edffd5",
      "metadata": {
        "id": "71edffd5"
      },
      "source": [
        "## 5) Split Train/Val/Test\n",
        "\n",
        "This dataset may not have labels, so we do a random split by default.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2c938a98",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-17T03:21:44.358534254Z",
          "start_time": "2026-02-17T03:21:43.385194579Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c938a98",
        "outputId": "eb3f56d5-3da0-42bb-8605-61cd15ac741f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(148847, 18605, 18607)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def random_split(df_in: pd.DataFrame, train=0.8, val=0.1, test=0.1, seed=RANDOM_SEED):\n",
        "    assert abs(train + val + test - 1.0) < 1e-9\n",
        "    idx = list(df_in.index)\n",
        "    rng = random.Random(seed)\n",
        "    rng.shuffle(idx)\n",
        "    n = len(idx)\n",
        "    n_train = int(n * train)\n",
        "    n_val = int(n * val)\n",
        "    train_df = df_in.loc[idx[:n_train]].reset_index(drop=True)\n",
        "    val_df = df_in.loc[idx[n_train:n_train+n_val]].reset_index(drop=True)\n",
        "    test_df = df_in.loc[idx[n_train+n_val:]].reset_index(drop=True)\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "train_df, val_df, test_df = random_split(df_clean, 0.8, 0.1, 0.1)\n",
        "\n",
        "len(train_df), len(val_df), len(test_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6018f07e",
      "metadata": {
        "id": "6018f07e"
      },
      "source": [
        "## 6) Build retrieval corpus (chunk answers)\n",
        "\n",
        "For a simple RAG baseline, we can index the **answers** (or combine question+answer).\n",
        "If you later add external guideline PDFs, replace this with guideline chunking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4897d682",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-17T03:22:02.372919086Z",
          "start_time": "2026-02-17T03:21:44.374270953Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4897d682",
        "outputId": "3bfed642-b763-4eb0-f828-98859199ca64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(                                     doc_id  \\\n",
              " 0  cf4f80246e8f4aa4527acde329e708728ef2fb85   \n",
              " 1  8a119092792fd342caa44cd757208b9b60b0cef2   \n",
              " 2  8a119092792fd342caa44cd757208b9b60b0cef2   \n",
              " 3  bf96be8699b1126bff81647bbe4bc236ae49e269   \n",
              " 4  bf96be8699b1126bff81647bbe4bc236ae49e269   \n",
              " \n",
              "                                        chunk_id  \\\n",
              " 0  cf4f80246e8f4aa4527acde329e708728ef2fb85-000   \n",
              " 1  8a119092792fd342caa44cd757208b9b60b0cef2-000   \n",
              " 2  8a119092792fd342caa44cd757208b9b60b0cef2-001   \n",
              " 3  bf96be8699b1126bff81647bbe4bc236ae49e269-000   \n",
              " 4  bf96be8699b1126bff81647bbe4bc236ae49e269-001   \n",
              " \n",
              "                                                 text  \n",
              " 0  Q: ผมโดนเเมวข่วนแมวยังไม่ฉีดยาพึ่งอายุ2เดือนกว...  \n",
              " 1  Q: เป็นเวลาหนึ่งสัปดาห์แล้วที่ฉันรู้สึกแสบท้อง...  \n",
              " 2  ราโซล 20 มก., แพนโทพราโซล 40 มก., โอเมพราโซล 2...  \n",
              " 3  Q: คืิผมอานุแค่14ครับมีตุ่ทที่โคนลิ้นเจ็บไม่เจ...  \n",
              " 4  เป็นอาการแสดงของโรคติดเชื้อต่างๆ เช่น โรคมือเท...  ,\n",
              " 225332)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def chunk_text(text: str, max_chars: int = 900, overlap: int = 120):\n",
        "    text = clean_text(text)\n",
        "    if not text:\n",
        "        return []\n",
        "    # sentence-ish split (Thai doesn't use periods consistently; still helps a bit)\n",
        "    sents = re.split(r\"(?<=[.!?。！？])\\s+\", text)\n",
        "    chunks, cur = [], \"\"\n",
        "    for s in sents:\n",
        "        if not s:\n",
        "            continue\n",
        "        if len(cur) + 1 + len(s) <= max_chars:\n",
        "            cur = (cur + \" \" + s).strip()\n",
        "        else:\n",
        "            if cur:\n",
        "                chunks.append(cur)\n",
        "            cur = s\n",
        "    if cur:\n",
        "        chunks.append(cur)\n",
        "\n",
        "    final = []\n",
        "    for ch in chunks:\n",
        "        if len(ch) <= max_chars:\n",
        "            final.append(ch)\n",
        "        else:\n",
        "            start = 0\n",
        "            while start < len(ch):\n",
        "                final.append(ch[start:start + max_chars])\n",
        "                start += max(1, max_chars - overlap)\n",
        "    return final\n",
        "\n",
        "def build_corpus(df_in: pd.DataFrame, max_chars=900):\n",
        "    rows = []\n",
        "    for _, r in df_in.iterrows():\n",
        "        doc_id = r[\"id\"]\n",
        "        # Index answer alone, or (Q+A) if you prefer:\n",
        "        base = f\"Q: {r['question']}\\nA: {r['answer']}\"\n",
        "        for j, ch in enumerate(chunk_text(base, max_chars=max_chars, overlap=max(20, int(max_chars*0.15)))):\n",
        "            rows.append({\"doc_id\": doc_id, \"chunk_id\": f\"{doc_id}-{j:03d}\", \"text\": ch})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "corpus_df = build_corpus(train_df, max_chars=900)\n",
        "corpus_df.head(), len(corpus_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9b5a470",
      "metadata": {
        "id": "b9b5a470"
      },
      "source": [
        "## 7) Export JSONL (+ audit files)\n",
        "\n",
        "Outputs:\n",
        "- `qa_train.jsonl`, `qa_val.jsonl`, `qa_test.jsonl`\n",
        "- `corpus.jsonl`\n",
        "- `pii_flagged.jsonl` (audit)\n",
        "- `sensitive_flagged.jsonl` (audit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ad6551d4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-17T03:22:07.332487254Z",
          "start_time": "2026-02-17T03:22:02.390511718Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad6551d4",
        "outputId": "3034f527-4144-4669-bc13-208189458d10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rows_total_parsed': 189190,\n",
              " 'rows_unparsed': 0,\n",
              " 'rows_after_filters': 186059,\n",
              " 'train': 148847,\n",
              " 'val': 18605,\n",
              " 'test': 18607,\n",
              " 'corpus_chunks_train': 225332,\n",
              " 'pii_flagged': 358,\n",
              " 'sensitive_flagged': 2667}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def to_jsonl(df_in: pd.DataFrame, path: str):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for row in df_in.to_dict(orient=\"records\"):\n",
        "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "outdir = \"out_thai_med_pack\"\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "to_jsonl(train_df.drop(columns=[\"raw_text\"]), os.path.join(outdir, \"qa_train.jsonl\"))\n",
        "to_jsonl(val_df.drop(columns=[\"raw_text\"]),   os.path.join(outdir, \"qa_val.jsonl\"))\n",
        "to_jsonl(test_df.drop(columns=[\"raw_text\"]),  os.path.join(outdir, \"qa_test.jsonl\"))\n",
        "to_jsonl(corpus_df, os.path.join(outdir, \"corpus.jsonl\"))\n",
        "\n",
        "if len(df_pii_flagged) > 0:\n",
        "    to_jsonl(df_pii_flagged, os.path.join(outdir, \"pii_flagged.jsonl\"))\n",
        "if len(df_sensitive_flagged) > 0:\n",
        "    to_jsonl(df_sensitive_flagged, os.path.join(outdir, \"sensitive_flagged.jsonl\"))\n",
        "\n",
        "stats = {\n",
        "    \"rows_total_parsed\": int(len(df)),\n",
        "    \"rows_unparsed\": int(len(unparsed)),\n",
        "    \"rows_after_filters\": int(len(df_clean)),\n",
        "    \"train\": int(len(train_df)),\n",
        "    \"val\": int(len(val_df)),\n",
        "    \"test\": int(len(test_df)),\n",
        "    \"corpus_chunks_train\": int(len(corpus_df)),\n",
        "    \"pii_flagged\": int(len(df_pii_flagged)),\n",
        "    \"sensitive_flagged\": int(len(df_sensitive_flagged)),\n",
        "}\n",
        "with open(os.path.join(outdir, \"stats.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(stats, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "stats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2de21585",
      "metadata": {
        "id": "2de21585"
      },
      "source": [
        "## 8) What to write in your proposal/report (copy-paste starter)\n",
        "\n",
        "**Dataset & Data Description**\n",
        "- Source: Hugging Face dataset `Thaweewat/thai-med-pack`\n",
        "- Modality: Thai medical Q&A instruction-style text\n",
        "- Size: ~189k rows (train split)\n",
        "- Split: Created locally (80/10/10)\n",
        "\n",
        "**Privacy / PDPA / Ethics**\n",
        "- Content may include sensitive health topics and minors; treat as potentially sensitive.\n",
        "- Mitigations: PII heuristic scan + sensitive-topic filter + audit outputs.\n",
        "- Risk if wrong: incorrect health guidance -> require disclaimers, escalation rules, and “decision-support only”.\n",
        "\n",
        "**Data Engineering**\n",
        "- Parse instruction format, dedupe, drop unparsed/empty.\n",
        "- Sampling: random split (no labels).\n",
        "- Assumptions: parsed Q/A reflect intended supervision signal; filtering reduces harmful/sensitive content exposure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfb5ce82",
      "metadata": {
        "id": "dfb5ce82"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cGeZFZ_p6c0m",
      "metadata": {
        "id": "cGeZFZ_p6c0m"
      },
      "source": [
        "**Feature หลักที่ใช้ (Engineered / Learned)**\n",
        "\n",
        "* **Combined Q&A Context (Engineered)**: การสร้าง String ชุดใหม่ที่รวมทั้งคำถามและคำตอบเข้าด้วยกัน (รูปแบบ `Q: {question} A: {answer}`) เพื่อให้แต่ละ Chunk มีความหมายที่สมบูรณ์ในตัวเองก่อนนำไปประมวลผล\n",
        "\n",
        "* **Semantic Chunks (Engineered)**: การแบ่งข้อความเป็นส่วนย่อย (Chunking) ขนาด 900 ตัวอักษร โดยมีส่วนที่ Overlap กัน 120 ตัวอักษร เพื่อรักษาความต่อเนื่องของเนื้อหาทางการแพทย์และป้องกันการขาดหายของบริบทที่รอยต่อ\n",
        "\n",
        "* **Multilingual MPNet Embeddings (Learned)**: การแปลงข้อความภาษาไทยให้เป็นเวกเตอร์ความหมายขนาด 768 มิติ โดยใช้โมเดล paraphrase-multilingual-mpnet-base-v2 เพื่อใช้ในกระบวนการ Semantic Search\n",
        "\n",
        "* **Content-Based Stable ID (Engineered)**: การสร้าง ID เฉพาะตัวด้วยการทำ SHA1 Hash จากเนื้อหา Q&A เพื่อใช้ระบุตัวตนของข้อมูลและป้องกันความซ้ำซ้อนในฐานข้อมูลเวกเตอร์\n",
        "\n",
        "**เหตุผลในการเลือก Feature**\n",
        "\n",
        "* **Semantic Mapping**: เลือกใช้ paraphrase-multilingual-mpnet-base-v2 เนื่องจากเป็นโมเดลที่ถูกฝึกมาเพื่อเน้นเรื่องการเปรียบเทียบความหมายของประโยค และรองรับภาษาไทยได้ดี ทำให้สามารถดึงข้อมูลที่เกี่ยวข้องได้แม้ผู้ใช้จะใช้คำถามที่ไม่ตรงกับ Keyword ในฐานข้อมูล\n",
        "\n",
        "* **Contextual Integrity**: การทำ Chunking พร้อม Overlap ช่วยให้ระบบ RAG สามารถเข้าถึงข้อมูลที่เป็นคำแนะนำทางการแพทย์ได้อย่างต่อเนื่องและลดความผิดพลาดในการสร้างคำตอบ\n",
        "\n",
        "**Feature ที่ตั้งใจไม่ใช้ (ถ้ามี)**\n",
        "\n",
        "* **Raw Instruction Tokens**: เช่น `<s>`, `[INST]`, `[/INST]`, `</s> `จะถูกคัดออกเนื่องจากเป็นสัญลักษณ์ควบคุมทางเทคนิคที่ไม่ส่งผลต่อความหมายในเชิงการค้นหา\n",
        "\n",
        "* **High-Risk Sensitive Mentions**: เนื้อหาที่เกี่ยวข้องกับภาวะวิกฤต เช่น การทำร้ายตัวเอง หรือการฆ่าตัวตาย ที่ถูก Flag ไว้ในขั้นตอนการทำความสะอาดข้อมูล จะไม่ถูกนำมาสร้างเป็น Feature เพื่อความปลอดภัยตามหลักจริยธรรมทางการแพทย์\n",
        "\n",
        "* **PII (Personally Identifiable Information)**: ข้อมูลส่วนบุคคล เช่น หมายเลขโทรศัพท์ หรือเลขประจำตัวประชาชน จะถูกคัดออกเพื่อปฏิบัติตามหลักความเป็นส่วนตัวของข้อมูลสุขภาพ (PDPA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd9c14d6",
      "metadata": {
        "id": "fd9c14d6"
      },
      "source": [
        "Text Embedding using `paraphrase-multilingual-mpnet-base-v2`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85d9412f",
      "metadata": {
        "id": "85d9412f"
      },
      "outputs": [],
      "source": [
        "# !pip install -U sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def generate_embeddings(df_corpus):\n",
        "    model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2', device=device)\n",
        "\n",
        "    sentences = df_corpus['text'].tolist()\n",
        "\n",
        "    embeddings = model.encode(\n",
        "        sentences,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_numpy=True,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "corpus_embeddings = generate_embeddings(corpus_df)\n",
        "np.save(\"out_thai_med_pack/corpus_embeddings.npy\", corpus_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "en31JAHGHRG9",
      "metadata": {
        "id": "en31JAHGHRG9"
      },
      "source": [
        "# Model Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hj1zR7QdHVGj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj1zR7QdHVGj",
        "outputId": "e42a5b2c-d457-4e0f-f035-2b68db895fab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.2)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-5.2.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (26.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu128)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (1.4.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (5.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (0.21.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub>=0.21.0->accelerate) (8.3.1)\n",
            "Downloading sentence_transformers-5.2.3-py3-none-any.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.2/494.2 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 5.2.2\n",
            "    Uninstalling sentence-transformers-5.2.2:\n",
            "      Successfully uninstalled sentence-transformers-5.2.2\n",
            "Successfully installed sentence-transformers-5.2.3\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.17.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.29.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.189.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.47.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.2)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.1 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n"
          ]
        }
      ],
      "source": [
        "# !pip install -U accelerate sentence-transformers\n",
        "# !pip install -q -U faiss-cpu\n",
        "# !pip install openai google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-6INpESMJ7nU",
      "metadata": {
        "id": "-6INpESMJ7nU"
      },
      "source": [
        "## load embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "JLYSN49qJaQX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "471df5a344434740b3d431a2f955b2a0",
            "38cb66b7e0d141139fa5f6cf0564fc93",
            "709b0297bac34fccb4ba7ba3e36072da",
            "6d6ba58884084cb0a0b796d7a9253047",
            "6d19e23777ae4223957400c1d70506ad",
            "311007da8e05438682fe5ad0d1393541",
            "2f8372f389c44b8ba6ae2762e202e050",
            "bef160ea03f04aafb594d2b516d46455",
            "6717b07029f14ddab7c938176e15799c",
            "ba447c39d6a74e1b989b7339866799cb",
            "55b45b2ee9b74689b3a6bba24b5fe048"
          ]
        },
        "id": "JLYSN49qJaQX",
        "outputId": "30b6c850-bf2a-4e4e-a908-e514954d0f16"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "471df5a344434740b3d431a2f955b2a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "XLMRobertaModel LOAD REPORT from: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "embed_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xPHQvNaCKJH2",
      "metadata": {
        "id": "xPHQvNaCKJH2"
      },
      "source": [
        "## RAG Knowledge Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a9h2uYWxGpAG",
      "metadata": {
        "id": "a9h2uYWxGpAG"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "embeddings = np.load(\"out_thai_med_pack/corpus_embeddings.npy\").astype('float32')\n",
        "\n",
        "d = embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(d)\n",
        "index.add(embeddings)\n",
        "\n",
        "medical_kb = corpus_df.to_dict('records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ygjdTeDkPxY5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygjdTeDkPxY5",
        "outputId": "f9fd9a04-343a-4e23-9e21-be8600ef650f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'doc_id': 'cf4f80246e8f4aa4527acde329e708728ef2fb85', 'chunk_id': 'cf4f80246e8f4aa4527acde329e708728ef2fb85-000', 'text': 'Q: ผมโดนเเมวข่วนแมวยังไม่ฉีดยาพึ่งอายุ2เดือนกว่าๆแบบนี้จะเป็นไรไหมครับแต่ผมเคยฉีดวัคซีนกันพิษสุนัขบ้ามาแล้วครับครบ5เข้มแบบนี้ผมต้องไปฉีดยาไหมครับรู้สึกไม่สบายใจ A: สวัสดีค่ะ โรคพิษสุนัขบ้านั้นเกิดเมื่อถูกสัตว์เลี้ยงลูกด้วยนมเช่น สุนัข แมว หนูกัด หรือไปสัมผัสสารคัดหลั่งของมันเข้าไปตรงแผลหรือเยื่อบุเช่น ในปาก โดยตรง โรคพิษสุนัขบ้าป้องกันได้ด้วยการฉีดวัคซีน 5 เข็ม และมีการกระตุ้นวัคซีนเมื่อถูกกัดซ้ำจากที่กล่าวมานั้น ถ้าเคยรับวัคซีนป้องกันพิษสุนัขบ้ามาครบ 5 เข็มแต่นานเกิน 6 เดือนมาแล้ว ควรจะไปกระตุ้น แม้ว่าจริงๆแล้วหากได้รับวัคซีนครบ 5 เข็มภูมิคุ้มกันจะอยู่สูงได้ประมาณ 1-2 ปีก็ตาม การกระตุ้นวัคซีนนั้น ถ้าถูกกัดมาภายใน 6 เดือน จะกระตุ้น 1 เข็ม ถ้าเกิน 6 เดือนกระตุ้น 2 เข็มห่างกัน 3 วัน'}\n"
          ]
        }
      ],
      "source": [
        "print(medical_kb[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TwIdgfMTKCBk",
      "metadata": {
        "id": "TwIdgfMTKCBk"
      },
      "source": [
        "## Candidate model setup\n",
        "- baseline model : gemini-3-flash-preview\n",
        "- candidate 1 : Gemma-SEA-LION-v4-27B-IT\n",
        "- candidate 2 : Kimi-K2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uwIpcz-GEvcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwIpcz-GEvcc",
        "outputId": "443690c4-2a45-403d-e74b-92af287c4934"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  loader.exec_module(module)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# candidate model list\n",
        "LLM_CHOICES = {\n",
        "    \"gemini\": { # baseline model\n",
        "        \"type\": \"gemini\",\n",
        "        \"api_key\": userdata.get(\"gemini_api\"), # get env in collab\n",
        "        \"model\": \"gemini-3-flash-preview\"\n",
        "    },\n",
        "    \"sealions\": { # candidate 1\n",
        "        \"type\": \"openai\",\n",
        "        \"api_key\": userdata.get('sealion_api'),\n",
        "        \"base_url\": \"https://api.sea-lion.ai/v1\",\n",
        "        \"model\": \"aisingapore/Gemma-SEA-LION-v4-27B-IT\"\n",
        "    },\n",
        "    \"kimi\": { # candidate 2\n",
        "        \"type\": \"openai\",\n",
        "        \"api_key\": userdata.get('openrouter_api'),\n",
        "        \"base_url\": \"https://openrouter.ai/api/v1\",\n",
        "        \"model\": \"moonshotai/Kimi-K2.5\"\n",
        "    },\n",
        "}\n",
        "def get_llm_client(provider_name):\n",
        "    config = LLM_CHOICES[provider_name]\n",
        "\n",
        "    if config[\"type\"] == \"openai\":\n",
        "        client = OpenAI(\n",
        "            api_key=config[\"api_key\"],\n",
        "            base_url=config[\"base_url\"]\n",
        "        )\n",
        "        return client, config[\"model\"], \"openai\"\n",
        "\n",
        "    if config[\"type\"] == \"gemini\":\n",
        "        genai.configure(api_key=config[\"api_key\"])\n",
        "        model = genai.GenerativeModel(config[\"model\"])\n",
        "        return model, config[\"model\"], \"gemini\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zeWXrLK0KYTv",
      "metadata": {
        "id": "zeWXrLK0KYTv"
      },
      "source": [
        "## Setup model context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "8bMmavDXI8oO",
      "metadata": {
        "id": "8bMmavDXI8oO"
      },
      "outputs": [],
      "source": [
        "def medical_rag_system(user_query, provider=\"kimi\", temperature = 0.1):\n",
        "    # Step: Search\n",
        "    query_embedding = embed_model.encode([user_query], normalize_embeddings=True)\n",
        "    _, indices = index.search(np.array(query_embedding).astype('float32'), k=1)\n",
        "\n",
        "    match = medical_kb[indices[0][0]]\n",
        "\n",
        "\n",
        "# FILL IN SYSTEM PROMPT HERE\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\"\"\n",
        "        คุณคือผู้ช่วยคัดกรองอาการผู้ป่วย\n",
        "        ใช้เฉพาะข้อมูลอ้างอิงที่ให้\n",
        "        ต้องตอบเป็น 3 ส่วน:\n",
        "        1. การประเมินอาการ\n",
        "        2. ระดับความรุนแรง\n",
        "        3. แผนกที่ควรไป\n",
        "        สรุปการแนะนำ\n",
        "        ตอบภาษาเดียวกับคำถาม\n",
        "        ห้ามทวนคำสั่ง\n",
        "        \"\"\"\n",
        "        },\n",
        "        {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": f\"\"\"\n",
        "ข้อมูลอ้างอิง:\n",
        "{match['text']}\n",
        "\n",
        "คำถาม:\n",
        "{user_query}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "    client, model_name, provider_type = get_llm_client(provider)\n",
        "    print(\"using model: \" + model_name)\n",
        "    if provider_type == \"openai\":\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=messages,\n",
        "            temperature=temperature,\n",
        "            max_tokens= 2048\n",
        "        )\n",
        "        answer = response.choices[0].message.content\n",
        "\n",
        "    elif provider_type == \"gemini\":\n",
        "        # Gemini expects single prompt string\n",
        "        full_prompt = \"\\n\".join([m[\"content\"] for m in messages])\n",
        "\n",
        "        response = client.generate_content(\n",
        "            full_prompt,\n",
        "            generation_config={\n",
        "                \"temperature\": temperature,\n",
        "                \"max_output_tokens\": 2048\n",
        "            }\n",
        "        )\n",
        "        answer = response.text\n",
        "\n",
        "    disclaimer = \"\\n\\n*หมายเหตุ: นี่คือการคัดกรองและการแนะนำเบื้องต้น ไม่ใช่การวินิจฉัยทางการแพทย์*\"\n",
        "    return answer + disclaimer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ajGCwiQFKcjy",
      "metadata": {
        "id": "ajGCwiQFKcjy"
      },
      "source": [
        "## Q&A Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "BN160388JpHM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "BN160388JpHM",
        "outputId": "00cc68ff-72c1-42e8-aba4-131c29c25a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'doc_id': '86c7c3cb40e11003486a9efa833d5fd9206a967b', 'chunk_id': '86c7c3cb40e11003486a9efa833d5fd9206a967b-000', 'text': 'Q: ฉันหายใจลำบากและแน่นหน้าอก ฉันยังรู้สึกหายใจติดขัด A: จากอาการของคุณ ดูเหมือนว่าคุณเป็นโรคหลอดลมอักเสบเฉียบพลัน'}\n",
            "Q: ฉันหายใจลำบากและแน่นหน้าอก ฉันยังรู้สึกหายใจติดขัด A: จากอาการของคุณ ดูเหมือนว่าคุณเป็นโรคหลอดลมอักเสบเฉียบพลัน\n",
            "using model: gemini-3-flash-preview\n",
            "ผลลัพธ์การคัดกรอง:\n",
            "1. **การประเมินอาการ**: จากอาการเจ็บหน้าอกมากและหายใจลำบาก ดูเหมือนว่าคุณเป็นโรคหลอดลมอักเสบเฉียบพลัน\n",
            "2. **ระดับความรุนแรง**: รุนแรง\n",
            "3. **แผนกที่ควรไป**: แผนกฉุกเฉิน หรือ แผนกอายุรกรรม\n",
            "\n",
            "**สรุปการแนะนำ**: เนื่องจากคุณมีอาการเจ็บหน้าอกและหายใจลำบาก ซึ่งเข้าข่ายอาการของโรคหลอดลมอักเสบเฉียบพลันตามข้อมูลอ้างอิง และมีความรุนแรงของอาการมาก ควรไปพบแพทย์ทันทีเพื่อรับการตรวจวินิจฉัยและรักษาอย่างเร่งด่วน\n",
            "\n",
            "*หมายเหตุ: นี่คือการคัดกรองและการแนะนำเบื้องต้น ไม่ใช่การวินิจฉัยทางการแพทย์*\n"
          ]
        }
      ],
      "source": [
        "query = \"เจ็บหน้าอกมาก หายใจลำบาก\"\n",
        "print(f\"ผลลัพธ์การคัดกรอง:\\n{medical_rag_system(query,provider=\"gemini\")}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ybWA901KiAD",
      "metadata": {
        "id": "4ybWA901KiAD"
      },
      "source": [
        "# **What to fill in proposal**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OetnyptFKj2J",
      "metadata": {
        "id": "OetnyptFKj2J"
      },
      "source": [
        "## LLM Model Selection\n",
        "\n",
        "## 1. Baseline Model: Gemini 3 Flash\n",
        "**Gemini 3 Flash** serves as the primary benchmark for this study due to its balance of speed and advanced reasoning.\n",
        "\n",
        "### Rationale for Selection\n",
        "* **Instruction Following:** Demonstrates high proficiency in complex reasoning and adhering to strict prompt constraints.\n",
        "* **Multilingual Support:** Native processing capabilities for Southeast Asian languages, specifically **Thai**.\n",
        "* **Task Stability:** Provides consistent performance across structured tasks such as classification, extraction, and summarization.\n",
        "* **Documentation:** Widely adopted and well-documented, making it an ideal reference point for comparative analysis.\n",
        "\n",
        "### Comparition metric\n",
        "![Artificial Analysis Intelligence Index](https://artificialanalysis.ai/img/articles/gemini-3-flash-everything-you-need-to-know/Artificial_Analysis_Intelligence_Index_%2816_Dec_25%29.png)\n",
        "\n",
        "---\n",
        "## 2. Candidate Models\n",
        "\n",
        "### A. SEA-LION (Gemma-based 27B Instruction-tuned)\n",
        "A model specifically architecturalized for the Southeast Asian (SEA) region.\n",
        "\n",
        "* **Key Strengths:**  Optimized for regional linguistic nuances.\n",
        "    * Strong alignment with local medical and cultural expressions.\n",
        "    * Open-weight architecture, providing greater deployment flexibility and private hosting capabilities.\n",
        "* **Comparison to Baseline:**  **Optimization** Regionally focused vs. Gemini’s global training.\n",
        "    * **Reasoning:** May trade off some general reasoning for superior local context.\n",
        "\n",
        "### B. Kimi 2.5\n",
        "A high-performance model known for its efficiency in handling large datasets.\n",
        "\n",
        "* **Key Strengths:**\n",
        "    * Exceptional **long-context handling** for processing lengthy documents.\n",
        "    * Strong structured output consistency.\n",
        "    * Competitive cost-to-performance ratio in production environments.\n",
        "* **Comparison to Baseline:**\n",
        "    * **Architecture:** Offers a different training approach compared to Google’s Gemini series.\n",
        "    * **Context:** Prioritizes maintaining coherence over massive input tokens.\n",
        "  ![kimi_metric](https://miro.medium.com/1*Ycy0aWssByBlhf0pb88CWg.png)\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Comparative Summary\n",
        "\n",
        "| Feature | Gemini 3 Flash (Baseline) | SEA-LION (27B) | Kimi 2.5 |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Optimization** | Global / General | Southeast Asian Regional | Long-Context / Efficiency\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-zD6gVmvKnqx",
      "metadata": {
        "id": "-zD6gVmvKnqx"
      },
      "source": [
        "### **Embedding Model** (Candidate)\n",
        "**1. bge-m3 :** vector embedding model\n",
        "![bge-m3](https://scontent.fbkk12-5.fna.fbcdn.net/v/t39.30808-6/504256971_3984009171837940_2984735354200405157_n.jpg?_nc_cat=110&ccb=1-7&_nc_sid=aa7b47&_nc_ohc=GrsYXizIJ2MQ7kNvwExDhEt&_nc_oc=AdmT3VCJlAgoYPWfAQemWXXsGkjvCu6BzgA1XwU5cW_9oXT36Lxmsr9_seJD8gv8q5A&_nc_zt=23&_nc_ht=scontent.fbkk12-5.fna&_nc_gid=7_oZaUIZbMQJeefqnBHPkA&oh=00_AfuxZNLD1XXfXyoSGVaizHACVPIaUWjCbVxvPA9zFXLKlQ&oe=699A4510)\n",
        "reference: https://huggingface.co/spaces/panuthept/thai_sentence_embedding_benchmark\n",
        "\n",
        "BGE-M3 is specifically trained to handle over 100 languages. In the context of our's project, it excels at Semantic Mapping—understanding that a patient’s casual description of a symptom (e.g., \"ปวดจี๊ดๆ ที่อก\") carries the same semantic weight as formal medical terms in our's database (e.g., \"Chest pain\" or \"Angina\").\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbUKLllDKtmh",
      "metadata": {
        "id": "bbUKLllDKtmh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.11.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f8372f389c44b8ba6ae2762e202e050": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "311007da8e05438682fe5ad0d1393541": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38cb66b7e0d141139fa5f6cf0564fc93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_311007da8e05438682fe5ad0d1393541",
            "placeholder": "​",
            "style": "IPY_MODEL_2f8372f389c44b8ba6ae2762e202e050",
            "value": "Loading weights: 100%"
          }
        },
        "471df5a344434740b3d431a2f955b2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38cb66b7e0d141139fa5f6cf0564fc93",
              "IPY_MODEL_709b0297bac34fccb4ba7ba3e36072da",
              "IPY_MODEL_6d6ba58884084cb0a0b796d7a9253047"
            ],
            "layout": "IPY_MODEL_6d19e23777ae4223957400c1d70506ad"
          }
        },
        "55b45b2ee9b74689b3a6bba24b5fe048": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6717b07029f14ddab7c938176e15799c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d19e23777ae4223957400c1d70506ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d6ba58884084cb0a0b796d7a9253047": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba447c39d6a74e1b989b7339866799cb",
            "placeholder": "​",
            "style": "IPY_MODEL_55b45b2ee9b74689b3a6bba24b5fe048",
            "value": " 199/199 [00:00&lt;00:00, 669.47it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "709b0297bac34fccb4ba7ba3e36072da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bef160ea03f04aafb594d2b516d46455",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6717b07029f14ddab7c938176e15799c",
            "value": 199
          }
        },
        "ba447c39d6a74e1b989b7339866799cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef160ea03f04aafb594d2b516d46455": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
